---
layout: post
title:  "Location and interaction services"
date:   2020-09-17 00:00:00 +0300
categories: VRSimulator posts
---
# Interaction platform

## Things we can interact with by touching
1. Button – press it: by using finger, distance – use a stick. Parameters: size, shape, height, force, 
2. Slider – like a button, move it around a line, fingers, stick, 
3. Touch Screen – precision is low. When interacting, because can’t see the surface, we can use some indicator like a lamp to show that user is already touching the screen, and doesn’t need to move the finger lower, or can move the screen together with the finger. Another way is using  a controller or stylus. Can also interact with a touchscreen connected to one of your hands with another hand, like in vrchat (\*).
4. Cube – touch 4 facing faces of the cube, each of them perform an action. Additional: can touch the edges with a virtual stick (\*), example: beatsaber, [mini beatsaber](https://vrscout.com/news/mini-beat-saber-oculus-quest-hand-tracking/)
5. Iron-man kind-of( transparent) touch screen (\*)
6. Switcher – on/off
7. Transparent button, just need to intersect with it, see example [here](https://medium.com/shopify-vr/expo-towards-rapid-vr-prototyping-15356d53ea71) (\*)

## Other ways to interact, not touch:
1. Microphone – just use the one inside VR headset. Can use voice commands
2. Speaker – Use Unity 3D sound, only according to the distance
3. Hand Gestures – connect two fingers, make a sign; i.e. [link](https://www.roadtovr.com/creative-uses-oculus-quest-hand-tracking-daniel-beauchamp/); hand walking(\*); throwing hands(\*); 
4. 
5. 

## How to interact with distant objects:
1. Make your hand much longer, hand tracking still works, you can operate with distant objects (\*)
2. Use a virtual saber (\*)
3. Throw your hand (\*)
4. 
… Editing…

## Other Items
1. Lamps: light color, intensity, cookie, halo, flare
 
(\*): Can only be performed in VR environment and at least for now can't be applied to real world

06-26:
I currently make a research on existing solutions for similar problems:

1. [Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments](https://www.frontiersin.org/articles/10.3389/fnbot.2018.00085/full) - the name speaks for itself;




            